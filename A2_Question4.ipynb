{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note 0 = business, 1 = entertainment, 2 = politics, 3 = sport, 4 = tech\n",
    "\n",
    "def load_extract_data():\n",
    "\n",
    "    classesFile = open('./bbc_folder/bbc.classes', 'r')\n",
    "    mtxFile = open('./bbc_folder/bbc.mtx', 'r')\n",
    "\n",
    "    numTerms = 9635\n",
    "\n",
    "    # read the lines in these 2 files which do not contribute to the data (the headers)\n",
    "    classesFile.readline(); classesFile.readline(); classesFile.readline(); classesFile.readline()\n",
    "    mtxFile.readline(); \n",
    "\n",
    "    # load the classes file into a numpy array and split the data so that we have a label for each article\n",
    "    array = np.loadtxt(classesFile, delimiter=\" \").astype(int)\n",
    "    (X, labels) = np.hsplit(array, 2)\n",
    "\n",
    "    # read the mtx matrix as a csv\n",
    "    df = pd.read_csv(mtxFile, delimiter=\" \").astype(int)\n",
    "\n",
    "    # define binary and frequency arrays for parts a) and b)\n",
    "    totalTermsBinary = np.empty((X.shape[0], 9635))\n",
    "    totalTermsFrequency = np.empty((X.shape[0], 9635))\n",
    "    \n",
    "    # for every article in which we have extracted the labels\n",
    "    for i in X:\n",
    "        index = i[0]+1\n",
    "        # get all the rows associated with the article i (column 2 of mtx)\n",
    "        articles = df.loc[df['2225'] == index]\n",
    "        termsBinary = np.zeros((numTerms))\n",
    "        termsFrequency = np.zeros((numTerms))\n",
    "\n",
    "        # get the columns with the term and the frequency of that term for each article in rows\n",
    "        foundTerms = articles[['9635', '286774']].to_numpy()\n",
    "\n",
    "        for (j,k) in foundTerms:\n",
    "            # If the term is in the article, assign the frequency/binary label to the corresponding term index\n",
    "            termsFrequency[j-1] = k\n",
    "            termsBinary[j-1] = 1\n",
    "\n",
    "        # Add the extracted data to our final data tables\n",
    "        totalTermsBinary[index-1] = termsBinary\n",
    "        totalTermsFrequency[index-1] = termsFrequency\n",
    "        \n",
    "    classesFile.close()\n",
    "    mtxFile.close()\n",
    "\n",
    "    return totalTermsBinary, totalTermsFrequency, labels\n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "(2225, 9635)\n",
      "-----------------------------------\n",
      "[[1. 5. 2. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 4. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "(2225, 9635)\n",
      "-----------------------------------\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [4]\n",
      " [4]\n",
      " [4]]\n",
      "(2225, 1)\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_binary, X_frequency, labels = load_extract_data()\n",
    "print(\"-----------------------------------\")\n",
    "print(X_binary)\n",
    "print(X_binary.shape)\n",
    "print(\"-----------------------------------\")\n",
    "print(X_frequency)\n",
    "print(X_frequency.shape)\n",
    "print(\"-----------------------------------\")\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data For Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1557, 9635)\n",
      "(668, 9635)\n",
      "(1557, 1)\n",
      "(668, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_binary, labels, test_size=0.30, train_size=0.70, random_state=20)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the initial probability of each class\n",
    "def get_class_probabilities(labels):\n",
    "    total = len(labels)\n",
    "    probability_of_c0 = (total - np.count_nonzero(labels)) / total\n",
    "    probability_of_c1 = np.count_nonzero(labels == 1) / total\n",
    "    probability_of_c2 = np.count_nonzero(labels == 2) / total\n",
    "    probability_of_c3 = np.count_nonzero(labels == 3) / total\n",
    "    probability_of_c4 = np.count_nonzero(labels == 4) / total\n",
    "\n",
    "    return probability_of_c0, probability_of_c1, probability_of_c2, probability_of_c3, probability_of_c4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22286448298008993 0.16955684007707128 0.19524727039177905 0.23249839434810532 0.1798330122029544\n"
     ]
    }
   ],
   "source": [
    "probability_of_c0, probability_of_c1, probability_of_c2, probability_of_c3, probability_of_c4 = get_class_probabilities(Y_train)\n",
    "print(probability_of_c0, probability_of_c1, probability_of_c2, probability_of_c3, probability_of_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability that if the term is in the article that it is the wanted label\n",
    "def get_probability(X_train, labels, term, wanted_label, total_counts):\n",
    "\n",
    "    count = 0\n",
    "    index = 0\n",
    "    for row in X_train:\n",
    "        # if we have the term is in the article type we want increment the count\n",
    "        if row[term] == 1 and labels[index] == wanted_label:\n",
    "            count+=1\n",
    "        index += 1\n",
    "    prob = (count + 1) / (total_counts[wanted_label] + 2)\n",
    "    return prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probability that if the term is not in the article it is label wanted_label\n",
    "def get_not_probability(X_train, labels, term, wanted_label, total_counts):\n",
    "    count = 0\n",
    "    index = 0\n",
    "    for row in X_train:\n",
    "        # If the term is not in our article type increment the count\n",
    "        if row[term] == 0 and labels[index] == wanted_label:\n",
    "            count+=1\n",
    "        index += 1\n",
    "    prob = (count + 1) / (total_counts[wanted_label] + 2)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_train(X_train, Y_train):\n",
    "\n",
    "    probTable = np.empty((9635, 10))\n",
    "\n",
    "    total_counts = np.bincount(Y_train[:,0])\n",
    "    for i in range(9635):\n",
    "        # probability that term i is 1 and leads to label 0\n",
    "        probTable[i][0] = get_probability(X_train, Y_train, i, 0, total_counts)\n",
    "        # Probability that term i not 1 and leads to label 0\n",
    "        probTable[i][1] = 1 - probTable[i][0]\n",
    "\n",
    "        # probability that term i is 1 and leads to label 1\n",
    "        probTable[i][2] = get_probability(X_train, Y_train, i, 1, total_counts)\n",
    "        # Probability that term i not 1 and leads to label 1\n",
    "        probTable[i][3] = 1- probTable[i][2]\n",
    "        \n",
    "        # probability that term i is 1 and leads to label 2\n",
    "        probTable[i][4] = get_probability(X_train, Y_train, i, 2, total_counts)\n",
    "        # Probability that term i not 1 and leads to label 2\n",
    "        probTable[i][5] = 1-probTable[i][4]\n",
    "\n",
    "        # probability that term i is 1 and leads to label 3\n",
    "        probTable[i][6] =  get_probability(X_train, Y_train, i, 3, total_counts)\n",
    "        # Probability that term i not 1 and leads to label 3\n",
    "        probTable[i][7] = 1 - probTable[i][6]\n",
    "\n",
    "        # probability that term i is 1 and leads to label 4\n",
    "        probTable[i][8] = get_probability(X_train, Y_train, i, 4, total_counts)\n",
    "        # Probability that term i not 1 and leads to label 4\n",
    "        probTable[i][9] = 1 - probTable[i][8]\n",
    "\n",
    "    return probTable\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26074499 0.73925501 0.22180451 ... 0.66208791 0.30141844 0.69858156]\n",
      " [0.30659026 0.69340974 0.18796992 ... 0.93956044 0.17730496 0.82269504]\n",
      " [0.17191977 0.82808023 0.04511278 ... 0.96428571 0.06382979 0.93617021]\n",
      " ...\n",
      " [0.00286533 0.99713467 0.0037594  ... 0.99725275 0.0141844  0.9858156 ]\n",
      " [0.00286533 0.99713467 0.0037594  ... 0.99725275 0.0141844  0.9858156 ]\n",
      " [0.00286533 0.99713467 0.0037594  ... 0.99725275 0.0106383  0.9893617 ]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = naive_bayes_train(X_train, Y_train)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(X_test, probabilities, Y_train):\n",
    "    prediction = np.empty((X_test.shape[0]))\n",
    "\n",
    "    init_prob0, init_prob1, init_prob2, init_prob3, init_prob4 = get_class_probabilities(Y_train)\n",
    "    init_prob0, init_prob1, init_prob2, init_prob3, init_prob4 = np.log(init_prob0), np.log(init_prob1), np.log(init_prob2), np.log(init_prob3), np.log(init_prob4)\n",
    "    \n",
    "    index = 0\n",
    "    for row in X_test:\n",
    "        prob0 = init_prob0\n",
    "        prob1 = init_prob1\n",
    "        prob2 = init_prob2\n",
    "        prob3 = init_prob3\n",
    "        prob4 = init_prob4\n",
    "\n",
    "        # find all terms that are not present in article\n",
    "        zeros = np.where(row == 0)\n",
    "        # find all terms that are present in article\n",
    "        ones = np.where(row == 1)\n",
    "\n",
    "\n",
    "        # get the total log probability where probabilities[ones][;,i] is all the rows where the term is 1 and the \n",
    "        # column i which is the probability that the term is in article i/2\n",
    "        prob0 += np.sum(np.log(probabilities[ones][:,0])) + np.sum(np.log(probabilities[zeros][:,1]))\n",
    "        prob1 += np.sum(np.log(probabilities[ones][:,2])) + np.sum(np.log(probabilities[zeros][:,3]))\n",
    "        prob2 += np.sum(np.log(probabilities[ones][:,4])) + np.sum(np.log(probabilities[zeros][:,5]))\n",
    "        prob3 += np.sum(np.log(probabilities[ones][:,6])) + np.sum(np.log(probabilities[zeros][:,7]))\n",
    "        prob4 += np.sum(np.log(probabilities[ones][:,8])) + np.sum(np.log(probabilities[zeros][:,9]))\n",
    "\n",
    "        \n",
    "        # Note for highest probability we just find the highest log and assign that class with the highest probability\n",
    "        maximum = max(prob0, prob1, prob2, prob3, prob4)\n",
    "\n",
    "        if prob0 == maximum:\n",
    "            prediction[index] = 0\n",
    "        elif prob1 == maximum:\n",
    "            prediction[index] = 1\n",
    "        elif prob2 == maximum:\n",
    "            prediction[index] = 2\n",
    "        elif prob3 == maximum:\n",
    "            prediction[index] = 3\n",
    "        else:\n",
    "            prediction[index] = 4\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = naive_bayes_predict(X_test, probabilities, Y_train)\n",
    "train_prediction = naive_bayes_predict(X_train, probabilities, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, labels):\n",
    "    same_element = 0\n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i] == labels[i]:\n",
    "            same_element += 1\n",
    "    return same_element / len(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:\n",
      "0.9890815671162492\n",
      "---------------------------\n",
      "Test Accuracy:\n",
      "0.9505988023952096\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = get_accuracy(test_prediction, Y_test)\n",
    "train_accuracy = get_accuracy(train_prediction, Y_train)\n",
    "\n",
    "print(\"Train Accuracy:\")\n",
    "print(train_accuracy)\n",
    "print(\"---------------------------\")\n",
    "print(\"Test Accuracy:\")\n",
    "print(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Class Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cov(data):\n",
    "    # calculate the variance of the data given that the features are independent as the TA said\n",
    "    var = np.var(data, axis=0)\n",
    "    # because TA said features are independent the covariance matrix is diagonal\n",
    "    cov = np.zeros((len(var), len(var)))\n",
    "    index = 0\n",
    "\n",
    "    for i in range(len(var)):\n",
    "        # if variance is 0 then add a small bias term\n",
    "        if(var[i] == 0):\n",
    "            cov[index][index] = 1e-7\n",
    "        else:\n",
    "            #if variance is non zero assign the variance to the diagonal\n",
    "            cov[index][index] = var[i]\n",
    "        index += 1\n",
    "\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGCC(data, labels):\n",
    "    # TODO: Complete function\n",
    "    labels = labels.flatten()\n",
    "    data_class0 = data[labels == 0]\n",
    "    data_class1 = data[labels == 1]\n",
    "    data_class2 = data[labels == 2]\n",
    "    data_class3 = data[labels == 3]\n",
    "    data_class4 = data[labels == 4]\n",
    "\n",
    "\n",
    "    # Calculate the covariance matrix for each class\n",
    "    cov0 = calculate_cov(data_class0)\n",
    "    cov1 = calculate_cov(data_class1)\n",
    "    cov2 = calculate_cov(data_class2)\n",
    "    cov3 = calculate_cov(data_class3)\n",
    "    cov4 = calculate_cov(data_class4)\n",
    "\n",
    "        # Calculate the means for each class\n",
    "    mean0 = np.mean(data_class0, axis=0)\n",
    "    mean1 = np.mean(data_class1, axis=0)\n",
    "    mean2 = np.mean(data_class2, axis=0)\n",
    "    mean3 = np.mean(data_class3, axis=0)\n",
    "    mean4 = np.mean(data_class4, axis=0)\n",
    "\n",
    "    return (mean0, cov0, mean1, cov1, mean2, cov2,\n",
    "             mean3, cov3, mean4, cov4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inverses(cov0, cov1, cov2, cov3, cov4):\n",
    "    inv_cov0 = np.zeros(cov0.shape)\n",
    "    inv_cov1 = np.zeros(cov1.shape)\n",
    "    inv_cov2 = np.zeros(cov2.shape)\n",
    "    inv_cov3 = np.zeros(cov3.shape)\n",
    "    inv_cov4 = np.zeros(cov4.shape)\n",
    "\n",
    "    # because the covariance matrices are diagonal the inverse is just the reciprocol of every element on the diagonal\n",
    "\n",
    "    np.fill_diagonal(inv_cov0, np.reciprocal(np.diag(cov0)))\n",
    "    np.fill_diagonal(inv_cov1, np.reciprocal(np.diag(cov1)))\n",
    "    np.fill_diagonal(inv_cov2, np.reciprocal(np.diag(cov2)))\n",
    "    np.fill_diagonal(inv_cov3, np.reciprocal(np.diag(cov3)))\n",
    "    np.fill_diagonal(inv_cov4, np.reciprocal(np.diag(cov4)))\n",
    "\n",
    "    return inv_cov0, inv_cov1, inv_cov2, inv_cov3, inv_cov4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_frequency, labels, test_size=0.30, train_size=0.70, random_state=20)\n",
    "\n",
    "(mean0, cov0, mean1, cov1, mean2, cov2, mean3, cov3, mean4, cov4) = trainGCC(X_train, Y_train)\n",
    "\n",
    "inv_cov0, inv_cov1, inv_cov2, inv_cov3, inv_cov4 = calculate_inverses(cov0, cov1, cov2, cov3, cov4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_gaussian(x, mean, cov, cov_inv):\n",
    "    # Note we can remove the 1/2pi ^d cuz that is a common scalar for all of them given that they all have same features\n",
    "    new_x = x.reshape(len(x), 1)\n",
    "    mean = mean.reshape(len(mean), 1)\n",
    "\n",
    "    # Because the covariance is diagonal, the determinant is the product of the diagonal\n",
    "    # Taking the log of that just leads to the sum of the log diagonals by log rules\n",
    "    cov_abs = np.sum(np.log(np.diag(cov)))\n",
    "    matrix1 = -0.5 * np.matmul(np.matmul((new_x-mean).T, cov_inv), (new_x-mean))\n",
    "\n",
    "    return  (-0.5) * cov_abs + matrix1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictGGC(X_test, Y_train, mean0, cov0, mean1, cov1, mean2, cov2, mean3, cov3, mean4, cov4):\n",
    "    \n",
    "    #get the initial class probabilities and log them since we are computing the log gaussian\n",
    "    init_prob0, init_prob1, init_prob2, init_prob3, init_prob4 = get_class_probabilities(Y_train)\n",
    "    init_prob0, init_prob1, init_prob2, init_prob3, init_prob4 = np.log(init_prob0), np.log(init_prob1), np.log(init_prob2), np.log(init_prob3), np.log(init_prob4) \n",
    "\n",
    "    prediction = np.empty((X_test.shape[0]))\n",
    "    index = 0\n",
    "    for row in X_test:\n",
    "        # find the gaussian for each class given the row\n",
    "        class0 = compute_log_gaussian(row, mean0, cov0, inv_cov0) + init_prob0\n",
    "        class1 = compute_log_gaussian(row, mean1, cov1, inv_cov1) + init_prob1\n",
    "        class2 = compute_log_gaussian(row, mean2, cov2, inv_cov2) + init_prob2\n",
    "        class3 = compute_log_gaussian(row, mean3, cov3, inv_cov3) + init_prob3\n",
    "        class4 = compute_log_gaussian(row, mean4, cov4, inv_cov4) + init_prob4\n",
    "\n",
    "        # The classification depends on which gaussian value is the largest\n",
    "        minimum = max(class0, class1, class2, class3, class4)\n",
    "\n",
    "        if class0 == minimum:\n",
    "            prediction[index] = 0\n",
    "        elif class1 == minimum:\n",
    "            prediction[index] = 1\n",
    "        elif class2 == minimum:\n",
    "            prediction[index] = 2\n",
    "        elif class3 == minimum:\n",
    "            prediction[index] = 3\n",
    "        else:\n",
    "            prediction[index] = 4\n",
    "\n",
    "        index += 1\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Both the test data and the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = predictGGC(X_test, Y_train, mean0, cov0, mean1, cov1, mean2, cov2, mean3, cov3, mean4, cov4)\n",
    "prediction_train = predictGGC(X_train, Y_train, mean0, cov0, mean1, cov1, mean2, cov2, mean3, cov3, mean4, cov4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:\n",
      "0.9131736526946108\n",
      "---------------------------\n",
      "Train Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(prediction_test, Y_test)\n",
    "print(\"Test Accuracy:\")\n",
    "print(accuracy)\n",
    "print(\"---------------------------\")\n",
    "accuracy_train = get_accuracy(prediction_train, Y_train)\n",
    "print(\"Train Accuracy:\")\n",
    "print(accuracy_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
